{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b2baf28-a152-44d9-86f0-ad8505351f6f",
   "metadata": {},
   "source": [
    "### For testing  \n",
    "Run it in terminal in the same directory  \n",
    "1. text_stats directly print  \n",
    "Run: python text_stats.py shakespear.txt \n",
    "\n",
    "2. text_stats write into a file  \n",
    "Run: python text_stats.py shakespear.txt test_save.txt  \n",
    "\n",
    "3. generate_text run  \n",
    "Run: python generate_text.py shakespear.txt the 500 \n",
    "\n",
    "4. generate_text with more words  \n",
    "Run: python generate_text.py shakespear.txt the 2000\n",
    "\n",
    "5. Write generate_text to file  \n",
    "We create a way to write the output of generate_text in to a file, but I think it is not required\n",
    "Run: python generate_text.py shakespear.txt the 2000 test_save.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26a58d5-9384-4793-860d-4aebe79cfd68",
   "metadata": {},
   "source": [
    "\n",
    "### Additional Questions\n",
    "  \n",
    "Q1.  \n",
    "In what way did you \"clean up\" or divide up the text into words (in the program; the text files should be left\n",
    "unaffected)? This does not have to be perfect in any sense, but it should at least avoid counting \"lord\",\n",
    "\"Lord\" and \"lord.\" as different words.  \n",
    "  \n",
    "A1:  \n",
    "Here we use `re` module to find the word, `re.findall(r\"\\b\\w+\\b\", text.lower())`\n",
    "This is used to find all pattern with \\b\\w+\\b pattern, r is use to let python use the string as pattern, where \\b is the boundary,\\w+ for one or more word charactors(number and underscore included). and we use  text.lower() to transform every characters into lower case to avoid counting in different words.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46d6b96-8aeb-4c81-bde2-be2d7ddb54e8",
   "metadata": {},
   "source": [
    "Q2.  \n",
    "Which data structures have you used (such as lists, tuples, dictionaries, sets, ...)? Why does that choice\n",
    "make sense? You do not have to do any extensive research on the topics, or try to find exotic modern data\n",
    "structures, but you should reflect on which of the standard data types (or variants thereof) make sense. If\n",
    "you have tried some other solution and updated your code later on, feel free to discuss the effects!\n",
    "    \n",
    "A2.  \n",
    "In our approach we manily use Counter object form collection module, this is similar to dictionary, which we can use the key to find the word and it's count using key. \n",
    "Also, it allows `most_common` method to sort Counter object from most appeared word(charactor) into a list of tuples, where the first element of the tuple is the word itself and the second element is the count.  \n",
    "We then use the list most_sommon prduced to print out the common word table.  \n",
    "We also use dictionary for getting all sucessor in function `\"compute_all_sucessors\"`. which will be used in text generation. This is because we need to store many layers of information, from the word itself, its' sucessor, and the counts of the sucessor. We then can find the required information we need using key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1190f1f4-a3f4-4665-9cbb-bb81b6460295",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
